technologies there is no doubt that the state of the art in speech synthesis
directly from unadorned text is extremely primitive at present
It is vital not to overemphasize the potential usefulness of abysmal speech
which takes a great deal of training on the part of the user before
it becomes at all intelligible  To make a rather extreme analogy
Morse code could be used as
audio output requiring a great deal of training but capable of being understood
at quite high rates by an expert
It could be generated very cheaply
But clearly the man in the street would find it quite unacceptable as
an audio output medium because of the excessive effort required to learn to use
it  In many applications very bad synthetic speech is just as useless
However the issue is complicated by the fact that for people who use
synthesizers regularly synthetic speech becomes quite easily comprehensible
We will return to the problem of evaluating the quality of artificial speech
later in the book Chapter 8
sh 17  System considerations for speech output
pp
Fortunately very many of the applications of speech output from computers
do not need to read unadorned text
In all the example systems described above except the reading machine
it is enough to be able to store utterances in some representation which can
include pre-programmed cues for pronunciation rhythm and intonation in
a much more explicit way than ordinary text does
pp
Of course techniques
for storing audio information have been in use for decades
For example a domestic cassette tape recorder stores speech at much better
than telephone quality at very low cost  The method of direct
recording of an analogue waveform is currently used for announcements in
the telephone network to provide information such as the time weather
forecasts and even bedtime stories
However it is difficult to provide rapid access to messages stored in
analogue form and although some computer peripherals which use analogue
recordings for voice-response applications have been marketed em they are
discussed briefly at the beginning of Chapter 3 em they have been
superseded by digital storage techniques
pp
Although direct storage of a digitized audio waveform is used in some
voice-response systems the approach has certain limitations  The most
obvious one is the large storage requirement  suitable coding can reduce
the data-rate of speech to as little as one hundredth of that needed by
direct digitization and textual representations reduce it by another factor
of ten or twenty  Of course the speech quality is inevitably compromised
somewhat by data-compression techniques  However the cost of storage is
dropping so fast that this is not necessarily an overriding factor
A more fundamental limitation is that utterances stored directly cannot sensibly
be modified in any way to take account of differing contexts
pp
If the results of certain kinds of analyses
of utterances are stored instead of simply the digitized waveform
a great deal more flexibility can be gained
It is possible to separate out the features of intonation and amplitude from
the articulation of the speech and this raises the attractive possibility
of regenerating utterances with pitch contours different from those with which they were
recorded
The primary analysis technique used for this purpose is
ul
linear prediction
of speech and this is treated in some detail in Chapter 6  It also reduces drastically the
data-rate of speech by a factor of around 50
It is likely that many voice-response systems in the short- and medium-term
future will use linear predictive representations for utterance storage
pp
For maximum flexibility however it is preferable to store a textual
representation of the utterance
There is an important distinction between speech
ul
storage
where an actual human utterance is recorded perhaps processed to lower
the data-rate and stored for subsequent regeneration when required
and speech
ul
synthesis
where the machine produces its own individual utterances which are not based
on recordings of a person saying the same thing  The difference is summarized
in Figure 15
FC Figure 15
In both cases something is stored  for the first it is
a direct representation of an actual human utterance while for the second
it is a typed
ul
description
of the utterance in terms of the sounds or phonemes which constitute it
The accent and tone of voice of the human speaker will be apparent in
the stored speech output while for synthetic speech the accent is the
machines and the tone of voice is determined by the synthesis program
pp
Probably the most attractive representation of utterances in man-machine
systems is ordinary English text as used by the Kurzweil reading machine
But as noted above this poses extraordinarily difficult problems for the
synthesis procedure and these inevitably result in severely degraded speech
Although in the very long term these problems may indeed be solved
most speech output systems can adopt as their representation of an utterance
a description of it which explicitly conveys the difficult features of
intonation rhythm and even pronunciation
In the kind of applications described above barring the reading machine
input will be prepared by a
programmer as he builds the software system which supports the interactive
dialogue
